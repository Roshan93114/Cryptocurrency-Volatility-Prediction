{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Cryptocurrency Volatility\n",
        "Prediction**"
      ],
      "metadata": {
        "id": "ctFSUffXn_ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "crypto-volatility/\n",
        "├─ data/                         # Raw or simulated data (CSV)\n",
        "├─ notebooks/\n",
        "│  ├─ 01_eda.ipynb\n",
        "│  ├─ 02_feature_engineering.ipynb\n",
        "│  └─ 03_modeling.ipynb\n",
        "├─ src/\n",
        "│  ├─ data_loader.py\n",
        "│  ├─ preprocess.py\n",
        "│  ├─ features.py\n",
        "│  ├─ models.py\n",
        "│  ├─ evaluate.py\n",
        "│  └─ pipeline.py\n",
        "├─ app/\n",
        "│  └─ streamlit_app.py\n",
        "├─ reports/\n",
        "│  ├─ EDA_Report.md\n",
        "│  ├─ HLD.md\n",
        "│  ├─ LLD.md\n",
        "│  ├─ Pipeline_Architecture.md\n",
        "│  └─ Final_Report.md\n",
        "├─ requirements.txt\n",
        "└─ README.md\n"
      ],
      "metadata": {
        "id": "MwFNcOYaoDYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python crypto-volatility/src/pipeline.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgETKsfioRdC",
        "outputId": "59d94e44-bd0d-4c77-8075-973f13b581e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/crypto-volatility/src/pipeline.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run crypto-volatility/app/streamlit_app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naSbe6CNocgD",
        "outputId": "61ffece6-5889-400b-ad58-1dcee24d8b3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: streamlit run [OPTIONS] [TARGET] [ARGS]...\n",
            "Try 'streamlit run --help' for help.\n",
            "\n",
            "Error: Invalid value: File does not exist: crypto-volatility/app/streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Core code\n",
        "1) Data simulation (50+ cryptos, OHLC, volume, market cap)"
      ],
      "metadata": {
        "id": "X7ohctIQoz18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# src/data_loader.py\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "def simulate_crypto_data(n_symbols=50, n_days=365, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    symbols = [f\"CRYPTO_{i}\" for i in range(1, n_symbols+1)]\n",
        "    dates = pd.date_range(\"2023-01-01\", periods=n_days)\n",
        "    rows = []\n",
        "    for sym in symbols:\n",
        "        base = 100 + np.cumsum(np.random.randn(n_days))  # random walk\n",
        "        high = base + np.random.rand(n_days) * 5\n",
        "        low = base - np.random.rand(n_days) * 5\n",
        "        open_ = base + np.random.randn(n_days)\n",
        "        close = base + np.random.randn(n_days)\n",
        "        volume = np.random.randint(5_000, 100_000, size=n_days)\n",
        "        market_cap = np.abs(close) * volume\n",
        "        for d in range(n_days):\n",
        "            rows.append([dates[d], sym, open_[d], high[d], low[d], close[d], volume[d], market_cap[d]])\n",
        "    return pd.DataFrame(rows, columns=[\"date\",\"symbol\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"market_cap\"])\n"
      ],
      "metadata": {
        "id": "zEJIysfro19v"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Preprocessing (missing values, scaling)"
      ],
      "metadata": {
        "id": "L4ViYxs2pC49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# src/preprocess.py\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def preprocess(df: pd.DataFrame):\n",
        "    df = df.copy()\n",
        "    df = df.dropna()\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "    df = df.sort_values([\"symbol\",\"date\"])\n",
        "    scaler = StandardScaler()\n",
        "    num_cols = [\"open\",\"high\",\"low\",\"close\",\"volume\",\"market_cap\"]\n",
        "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "    return df, scaler\n"
      ],
      "metadata": {
        "id": "J5MbfqmmonvB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Feature engineering (MA, rolling volatility, Bollinger Bands, ATR, liquidity)"
      ],
      "metadata": {
        "id": "PMD-6hC2pSl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# src/features.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def add_features(df: pd.DataFrame):\n",
        "    df = df.copy()\n",
        "    df[\"price_range\"] = df[\"high\"] - df[\"low\"]\n",
        "    df[\"volatility_7\"] = df.groupby(\"symbol\")[\"close\"].transform(lambda x: x.rolling(7).std())\n",
        "    df[\"ma_7\"] = df.groupby(\"symbol\")[\"close\"].transform(lambda x: x.rolling(7).mean())\n",
        "    df[\"ma_21\"] = df.groupby(\"symbol\")[\"close\"].transform(lambda x: x.rolling(21).mean())\n",
        "    df[\"bb_upper_21\"] = df[\"ma_21\"] + 2*df.groupby(\"symbol\")[\"close\"].transform(lambda x: x.rolling(21).std())\n",
        "    df[\"bb_lower_21\"] = df[\"ma_21\"] - 2*df.groupby(\"symbol\")[\"close\"].transform(lambda x: x.rolling(21).std())\n",
        "    # ATR (approx): rolling mean of high-low\n",
        "    df[\"atr_14\"] = df.groupby(\"symbol\")[\"price_range\"].transform(lambda x: x.rolling(14).mean())\n",
        "    df[\"liquidity_ratio\"] = df[\"volume\"] / (df[\"market_cap\"] + 1e-6)\n",
        "    df = df.dropna()\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "wN6sNm18pX_j"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Modeling (Linear Regression, Random Forest, XGBoost optional)"
      ],
      "metadata": {
        "id": "NhKczIkDpakT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# src/models.py\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def get_models():\n",
        "    return {\n",
        "        \"LinearRegression\": LinearRegression(),\n",
        "        \"RandomForest\": RandomForestRegressor(n_estimators=200, max_depth=None, random_state=42)\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "59N_XYQbpghD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Evaluation (RMSE, MAE, R²)"
      ],
      "metadata": {
        "id": "zD9vEFaFpl9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# src/evaluate.py\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    return {\n",
        "        \"RMSE\": float(np.sqrt(mean_squared_error(y_true, y_pred))),\n",
        "        \"MAE\": float(mean_absolute_error(y_true, y_pred)),\n",
        "        \"R2\": float(r2_score(y_true, y_pred))\n",
        "    }\n"
      ],
      "metadata": {
        "id": "xA4XF0DdpkyA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Pipeline (end‑to‑end)\n"
      ],
      "metadata": {
        "id": "WFm7i-1OpxXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# src/pipeline.py\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "# The following imports are removed, assuming functions are globally available\n",
        "# from data_loader import simulate_crypto_data\n",
        "# from preprocess import preprocess\n",
        "# from features import add_features\n",
        "# from models import get_models\n",
        "# from evaluate import evaluate\n",
        "\n",
        "def run_pipeline():\n",
        "    df = simulate_crypto_data(n_symbols=50, n_days=365)\n",
        "    df, scaler = preprocess(df)\n",
        "    df = add_features(df)\n",
        "\n",
        "    features = [\"open\",\"high\",\"low\",\"close\",\"volume\",\"market_cap\",\n",
        "                \"price_range\",\"ma_7\",\"ma_21\",\"bb_upper_21\",\"bb_lower_21\",\n",
        "                \"atr_14\",\"liquidity_ratio\"]\n",
        "    target = \"volatility_7\"\n",
        "\n",
        "    X, y = df[features], df[target]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    models = get_models()\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "        results[name] = evaluate(y_test, preds)\n",
        "\n",
        "    # Hyperparameter tuning for RandomForest\n",
        "    grid = GridSearchCV(models[\"RandomForest\"],\n",
        "                        param_grid={\"n_estimators\":[100,200], \"max_depth\":[5,10,None]},\n",
        "                        cv=3, n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "    tuned_preds = grid.best_estimator_.predict(X_test)\n",
        "    results[\"RandomForest_Tuned\"] = evaluate(y_test, tuned_preds)\n",
        "\n",
        "    pd.DataFrame(results).T.to_csv(\"reports/model_evaluation.csv\")\n",
        "    with open(\"reports/best_params.txt\",\"w\") as f:\n",
        "        f.write(str(grid.best_params_))\n",
        "\n",
        "    print(\"Pipeline complete. Results saved to reports/\")\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_pipeline()"
      ],
      "metadata": {
        "id": "10r_k8eIp1UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Streamlit app (local deployment)\n",
        "python"
      ],
      "metadata": {
        "id": "3Z6Y8sv6p9CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# app/streamlit_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from data_loader import simulate_crypto_data\n",
        "from preprocess import preprocess\n",
        "from features import add_features\n",
        "from models import get_models\n",
        "\n",
        "st.title(\"Cryptocurrency Volatility Prediction\")\n",
        "\n",
        "st.markdown(\"Upload data or use simulated dataset to predict 7-day rolling volatility.\")\n",
        "\n",
        "use_sim = st.checkbox(\"Use simulated dataset\", value=True)\n",
        "if use_sim:\n",
        "    df = simulate_crypto_data(n_symbols=10, n_days=180)\n",
        "else:\n",
        "    file = st.file_uploader(\"Upload CSV with columns: date, symbol, open, high, low, close, volume, market_cap\")\n",
        "    if file:\n",
        "        df = pd.read_csv(file)\n",
        "    else:\n",
        "        st.stop()\n",
        "\n",
        "df, scaler = preprocess(df)\n",
        "df = add_features(df)\n",
        "\n",
        "features = [\"open\",\"high\",\"low\",\"close\",\"volume\",\"market_cap\",\n",
        "            \"price_range\",\"ma_7\",\"ma_21\",\"bb_upper_21\",\"bb_lower_21\",\n",
        "            \"atr_14\",\"liquidity_ratio\"]\n",
        "target = \"volatility_7\"\n",
        "\n",
        "st.subheader(\"Sample data\")\n",
        "st.dataframe(df.head())\n",
        "\n",
        "models = get_models()\n",
        "model_choice = st.selectbox(\"Model\", list(models.keys()))\n",
        "model = models[model_choice]\n",
        "X, y = df[features], df[target]\n",
        "model.fit(X, y)\n",
        "\n",
        "st.subheader(\"Predict volatility for latest rows\")\n",
        "n = st.slider(\"Rows to predict\", 5, 50, 10)\n",
        "preds = model.predict(X.tail(n))\n",
        "out = df.tail(n)[[\"date\",\"symbol\"]].copy()\n",
        "out[\"predicted_volatility_7\"] = preds\n",
        "st.dataframe(out)\n"
      ],
      "metadata": {
        "id": "DVpGke2HqEEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA notebook highlights\n",
        "Trends: Moving averages vs close price to visualize momentum.\n",
        "\n",
        "Distributions: Histograms of volatility, ATR, liquidity ratio.\n",
        "\n",
        "Correlations: Heatmap of engineered features vs target.\n",
        "\n",
        "Insights: Liquidity ratio and ATR often correlate with short‑term volatility; MA gaps (MA7−MA21) capture trend shifts."
      ],
      "metadata": {
        "id": "8cYS3_abqPoc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documentation\n",
        "High‑level design (HLD)\n",
        "Goal: Predict short‑term volatility (7‑day rolling std of close).\n",
        "\n",
        "Inputs: OHLC, volume, market cap.\n",
        "\n",
        "Processing: Scaling → feature engineering (MA, Bollinger, ATR, liquidity).\n",
        "\n",
        "Models: Linear Regression, Random Forest (+tuning).\n",
        "\n",
        "Outputs: Predictions, evaluation metrics, simple UI via Streamlit."
      ],
      "metadata": {
        "id": "0tuBnpmOqUIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Low‑level design (LLD)\n",
        "data_loader.py: Simulates realistic price paths and market variables.\n",
        "\n",
        "preprocess.py: Cleans, sorts, scales numeric columns.\n",
        "\n",
        "features.py: Grouped rolling features per symbol; drops NaNs post‑rolling.\n",
        "\n",
        "models.py: Model registry for easy swapping.\n",
        "\n",
        "pipeline.py: Train/test split, training, evaluation, grid search, artifact saving.\n",
        "\n",
        "app/streamlit_app.py: Interactive predictions on latest rows."
      ],
      "metadata": {
        "id": "eNhcrv-EqYvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline architecture\n",
        "Ingest: Simulated/real CSV → DataFrame.\n",
        "\n",
        "Preprocess: Clean, scale, sort by symbol/date.\n",
        "\n",
        "Feature engineering: Rolling stats per symbol.\n",
        "\n",
        "Train: Fit baseline + tuned model.\n",
        "\n",
        "Evaluate: RMSE, MAE, R²; save results.\n",
        "\n",
        "Serve: Streamlit app for local testing.\n"
      ],
      "metadata": {
        "id": "1B1mDsCsqcKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final report (summary)\n",
        "Objective: Forecast short‑term volatility to support risk management and trading decisions.\n",
        "\n",
        "Best model: Random Forest (tuned) typically outperforms Linear Regression due to non‑linear relationships.\n",
        "\n",
        "Key features: ATR, liquidity ratio, price range, MA7/MA21, Bollinger bands.\n",
        "\n",
        "Performance: Reported via RMSE/MAE/R²; values depend on dataset realism and window sizes.\n",
        "\n",
        "Limitations: Synthetic data lacks regime shifts and real market microstructure; for production, use real datasets and robust validation (walk‑forward, time‑series split).\n",
        "\n",
        "Next steps: Add time‑aware CV, more indicators (RSI, MACD), LSTM/Temporal Fusion Transformer, and model monitoring."
      ],
      "metadata": {
        "id": "h4o49VqQqjGH"
      }
    }
  ]
}